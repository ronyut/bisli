{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center>\n",
    "        <img src=\"assets/img/dbconfig.png\" width=\"10%\" height=\"10%\" alt=\"imports and Excel reading and configuration\">\n",
    "        #Imports and Excel reading and configuration:\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import codecs, difflib, Levenshtein\n",
    "import re # regex\n",
    "\n",
    "'''\n",
    "Pandas Definitions\n",
    "'''\n",
    "df = pd.read_excel (r'../../docs/220819 - ALL data merged from natalia for shahar.xlsx', skiprows = 1) #(use \"r\" before the path string to address special character, such as '\\')\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "'''\n",
    "DEFINITIONS\n",
    "'''\n",
    "RUSSIAN = \"russian\"\n",
    "HEBREW = \"hebrew\"\n",
    "# languages and their range in the excel file (column numbers)\n",
    "LANGUAGES = {HEBREW: [\"EL\", \"GO\"], RUSSIAN: [\"CH\", \"EK\"]}\n",
    "# vowels\n",
    "VOWELS = \"aeiou\"\n",
    "CONSONANTS = \"qwrtyplkjhgfdszxcvbnm\"\n",
    "# symbols to be replaced\n",
    "REPLACE_SYMBOLS =  {'ç': 'c', '\"': \"'\", \"-\": \" \"}\n",
    "# Hebrew: symbols to be removed. Don't add / because we need to remove N/A\n",
    "REMOVE_SYMBOLS_RUS = \"_*.,`?()/\"\n",
    "REMOVE_SYMBOLS_HEB = REMOVE_SYMBOLS_RUS + \"'\"\n",
    "# check for transcribers' typos in words?\n",
    "CHECK_FOR_TYPOS = False\n",
    "# word similarity threshold\n",
    "SIMILARITY_THRESHOLD = 0.7\n",
    "# inspection list of possible errors and inaccuracies\n",
    "INSPECT = list()\n",
    "# do advanced replacements? (like v-f swaps and CVC mil'el vowel swaps)\n",
    "ADVANCED_LANG_REPLACE = False\n",
    "\n",
    "'''\n",
    "HEBREW\n",
    "'''\n",
    "# allowed difference combinations of words (Hebrew)\n",
    "ALLOWED_DIFF_HEB = [\"chx\", \"hx\", \"kq\", \"iy\", \"fv\"]\n",
    "# allowed letters in word differnce (Hebrew)\n",
    "ALLOWED_LETTERS_HEB = set(\"\".join(ALLOWED_DIFF_HEB) + \"aei\")\n",
    "\n",
    "# Letters and their possible replacements (Hebrew)\n",
    "# NOTE: make sure all the letters in LETTER_REPLACEMENTS_HEB are also in ALLOWED_DIFF_HEB list or appended to ALLOWED_LETTERS_HEB!\n",
    "LETTER_REPLACEMENTS_HEB = [{\"h\": [\"i\", \"y\"], \"i\": [\"y\", \"h\"], \"y\": [\"i\", \"h\"], \"f\": [\"v\"], \"v\": [\"f\"]},\n",
    "                       {\"k\": [\"q\"], \"ch\": [\"h\", \"x\"], \"h\": [\"x\", \"ch\"], \"x\": [\"h\", \"ch\"]}]\n",
    "\n",
    "'''\n",
    "Russian\n",
    "'''\n",
    "# prohobited letters in word differnce (Russian)\n",
    "PROHIBITED_LETTERS_RUS =  set(\"rpfglmnbvqwrtsxd\" + \"'\" + VOWELS)\n",
    "ALLOWED_LETTERS_RUS = set(\"jyh\")\n",
    "\n",
    "# Letters and their possible replacements (Russian)\n",
    "# NOTE: make sure all the letters in LETTER_REPLACEMENTS_RUS are also in ALLOWED_DIFF_RUS list or in ALLOWED_LETTERS_RUS!\n",
    "LETTER_REPLACEMENTS_RUS = {\"j\": [\"y\", \"i\"], \"y\": [\"i\"]} # \"y\" for plural; \"j\": e.g. esli - jesli - yesli\n",
    "\n",
    "'''\n",
    "BOTH\n",
    "'''\n",
    "BOTH = \"both\"\n",
    "# transcriptions\n",
    "heb_rep_phase_1 = {\"c'\":\"צ\", \"b\": \"ב\", \"g\": \"ג\", \"d\": \"ד\", \"sh\": \"ש\", \"v\": \"ב/ו\", \"h\": \"ה\", \"z\": \"ז\", \"x\": \"ח\", \"t\": \"ת\", \"'\": \"ע\", \"y\": \"י\", \"k\": \"כ\", \"l\": \"ל\", \"m\": \"מ\", \"n\": \"נ\", \"s\": \"ס\", \"p\": \"פ\", \"q\": \"ק\", \"r\": \"ר\"}\n",
    "heb_rep_phase_2 = {\"a\": \"א\", \"e\": \"א\", \"i\": \"א\", \"o\": \"א\", \"u\": \"א\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "        <img src=\"assets/img/freq.png\" width=\"20%\" height=\"20%\" alt=\"Find words frequencies\">\n",
    "        <h3>Find words frequencies:</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "repl_symbols: takes a string and removes specific symbols from it\n",
    "'''\n",
    "def repl_symbols(string, lang):    \n",
    "    if lang == HEBREW:\n",
    "        remove_symbols = REMOVE_SYMBOLS_HEB\n",
    "    elif lang == RUSSIAN:\n",
    "        remove_symbols = REMOVE_SYMBOLS_RUS\n",
    "    \n",
    "    for a, b in REPLACE_SYMBOLS.items():\n",
    "        string = string.replace(a, b)\n",
    "    for a in remove_symbols:\n",
    "        string = string.replace(a, '')\n",
    "    return string\n",
    "\n",
    "'''\n",
    "hasDigits: checks if a word has digits in it or at sign (@) which indicates that the word is innovative\n",
    "'''\n",
    "def hasDigits(string):\n",
    "    return any(char.isdigit() for char in string)\n",
    "\n",
    "'''\n",
    "loop_freq: returns a dictionary of each word in the dataframe and its frequency (sorted by frequency DESC)\n",
    "'''\n",
    "def loop_freq(col, lang):\n",
    "    freq = {}\n",
    "    \n",
    "    for row in col:\n",
    "        # skip NaN cells (empty cell)\n",
    "        if isinstance(row, (bool, float)) and str(row).lower() == \"nan\" or str(row) == \"\":\n",
    "            continue\n",
    "            \n",
    "        row = str(row)\n",
    "        # inspect cells with numbers\n",
    "        if hasDigits(row) and \"CS\" not in row:\n",
    "            INSPECT.append(row)\n",
    "            continue\n",
    "            \n",
    "        split = repl_symbols(row, lang).split(' ')\n",
    "        for word in split:\n",
    "            # ignore marks and short words and child's mistakes (usually capitalized)\n",
    "            if len(word) < 3 or \"@\" in word or \"xx\" in word or \"XX\" in word or word != word.lower():\n",
    "                continue\n",
    "            if word in freq:\n",
    "                freq[word] += 1\n",
    "            else:\n",
    "                freq[word] = 1            \n",
    "\n",
    "    # delete keys\n",
    "    keys_del = ['CORRECT', 'n/a', 'N/A', 'N/a', 'n/A']\n",
    "    for key in keys_del:\n",
    "        if key in freq:\n",
    "            del freq[key]\n",
    "\n",
    "    freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "    freq = collections.OrderedDict(freq)\n",
    "        \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"assets/img/rus-il.png\" width=\"13%\" height=\"13%\" alt=\"Shared functions for both languages\">\n",
    "    <h3>Functions for both languages:</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "hasVCV: checks if a string has a vowel-consonant-vowel, e.g. imAHOt\n",
    "'''\n",
    "def hasVCV(string, vowel = VOWELS, consonant = CONSONANTS):\n",
    "    return bool(re.search(\"[\"+ vowel +\"][\"+ consonant +\"][\" + vowel + \"]\", string))\n",
    "\n",
    "\n",
    "'''\n",
    "hasCVC: checks if a string has a consonant-vowel-consonant, e.g. imAHOt\n",
    "        Note: by default milra is allowed\n",
    "'''\n",
    "def hasCVC(string, vowel = VOWELS, consonant = CONSONANTS, milra = True):\n",
    "    pattern = \"[\"+ consonant +\"][\"+ vowel +\"][\" + consonant + \"]\"\n",
    "    regex = re.search(pattern, string)\n",
    "                 \n",
    "    # don't allow milra, i.e. don't match in end of line, UNLESS the word can't have milra (it's too short)\n",
    "    if milra or (not milra and len(string) <= 4):\n",
    "        return bool(regex)\n",
    "    else:\n",
    "        # Check also if the string has the CVC at all.\n",
    "        # Note: we remove only the 2 last chars from string because if we removed 3 we might lose CVC\n",
    "        # e.g. if we take \"xamor\" and remove 2 chars from the end, we'll get \"xa\" (not CVC) instead of \"xam\"\n",
    "        return (bool(regex) and hasCVC(string[:-2], vowel, consonant))\n",
    "\n",
    "'''\n",
    "hasVC: checks if a string has a vowel-consonant, e.g. cAT\n",
    "'''\n",
    "def hasVC(string, vowel = VOWELS, consonant = CONSONANTS):\n",
    "    return bool(re.search(\"[\"+ vowel +\"][\"+ consonant + \"]\", string))\n",
    "\n",
    "\n",
    "'''\n",
    "hasCV: checks if a string has a consonant-vowel, e.g. BAg\n",
    "'''\n",
    "def hasCV(string, vowel = VOWELS, consonant = CONSONANTS):\n",
    "    return bool(re.search(\"[\" + consonant +\"][\" + vowel + \"]\", string))\n",
    "\n",
    "\n",
    "'''\n",
    "isSamePair: check if a pair of strings are equal to other pair of strings\n",
    "'''\n",
    "def isSamePair(s1, s2, t1, t2):\n",
    "    if (s1 == t1 and s2 == t2) or (s1 == t2 and s2 == t1):\n",
    "        print(s1, s2, \"same!\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "'''\n",
    "doesPairInclude: check if a pair of strings indlude another pair of substrings\n",
    "'''\n",
    "def doesPairInclude(s1, s2, t1, t2):\n",
    "    if (s1 in t1 and s2 in t2) or (s1 in t2 and s2 in t1):\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "'''\n",
    "hasOnly: checks if a string has only specific letters\n",
    "'''\n",
    "def hasOnly(string, letters):\n",
    "    for s in string:\n",
    "        if s not in letters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "'''\n",
    "isEqualOnRemove: takes two substring and two strings, and checks whether both strings contain one substring.\n",
    "             Then remove the substrings from the strings\n",
    "'''\n",
    "def isEqualOnRemove(sub1, sub2, str1, str2):\n",
    "    if (sub1 in str1 and sub2 in str2) or (sub1 in str2 and sub2 in str1):\n",
    "        # now remove \n",
    "        str1 = str1.replace(sub1, \"\").replace(sub2, \"\")\n",
    "        str2 = str2.replace(sub1, \"\").replace(sub2, \"\")\n",
    "        if str1 == str2:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "'''\n",
    "removeSharedLetters: takes two strings and removes common letters, i.e. letters both share\n",
    "                     Note: the result of removeSharedLetters(\"abb\", \"a\") is ['b'] and not ['b', 'b']\n",
    "'''\n",
    "def removeSharedLetters(x, y):\n",
    "    count = lambda x: collections.Counter(c for c in x.lower())\n",
    "    cx, cy = count(x), count(y)\n",
    "    diff  = cx - cy\n",
    "    rev_diff = cy - cx    \n",
    "    rev_diff = list(rev_diff)\n",
    "    diff = list(diff)\n",
    "    \n",
    "    return sorted(rev_diff + diff)\n",
    "\n",
    "'''\n",
    "isEdgeLettersSame: checks if the edge letters are the same\n",
    "                   @param applyTo: do we want to compare only the beginnings, or the ends or maybe both.\n",
    "                                   accepts: [\"start\", \"end\", \"both\"]\n",
    "'''\n",
    "def isEdgeLettersSame(s1, s2, exceptions, applyTo = \"both\"):\n",
    "    startOk = False\n",
    "    endOk = False\n",
    "    s1_body = s1\n",
    "    s2_body = s2\n",
    "    \n",
    "    # if the first letter of each word aren't the same - don't merge\n",
    "    if applyTo in [\"start\", \"both\"] and s1[0] != s2[0]:\n",
    "        for orig, rep in exceptions.items():\n",
    "            # check if s1 or s2 begins with orig at all\n",
    "            if s1[0:len(orig)] == orig or s2[0:len(orig)] == orig:\n",
    "                # determine who begins with orig\n",
    "                hasOrig = s1 if s1[0:len(orig)] == orig else s2\n",
    "                noOrig = s1 if s1[0:len(orig)] != orig else s2\n",
    "                for r in rep:\n",
    "                    if (noOrig[0:len(r)] == r):\n",
    "                        startOk = True\n",
    "                        # update the bodies start\n",
    "                        if s1 == hasOrig:\n",
    "                            s1_body = s1_body[len(orig):]\n",
    "                            s2_body = s2_body[len(r):]\n",
    "                        else:\n",
    "                            s1_body = s1_body[len(r):]\n",
    "                            s2_body = s2_body[len(orig):]\n",
    "                            \n",
    "                        break\n",
    "    else:\n",
    "        startOk = True\n",
    "    \n",
    "    \n",
    "    # if the last letter of each word aren't the same - don't merge\n",
    "    if applyTo in [\"end\", \"both\"] and s1[-1] != s2[-1]:\n",
    "        for orig, rep in exceptions.items():\n",
    "            # check if s1 or s2 ends with orig at all\n",
    "            if s1[-len(orig):] == orig or s2[-len(orig):] == orig:\n",
    "                # determine who ends with orig and who doesn't\n",
    "                hasOrig = s1 if s1[-len(orig):] == orig else s2\n",
    "                noOrig = s1 if s1[-len(orig):] != orig else s2\n",
    "                for r in rep:\n",
    "                    if (noOrig[-len(r):] == r):\n",
    "                        endOk = True\n",
    "                        # update the bodies end\n",
    "                        if s1 == hasOrig:\n",
    "                            s1_body = s1_body[:-len(orig)]\n",
    "                            s2_body = s2_body[:-len(r)]\n",
    "                        else:\n",
    "                            s1_body = s1_body[:-len(r)]\n",
    "                            s2_body = s2_body[:-len(orig)]\n",
    "                        break\n",
    "    else:\n",
    "        endOk = True\n",
    "    \n",
    "    # if the words edges are the same, remove one char at the beginning and at the end\n",
    "    # I am still checking if it's better to not do it (@Rony, 24-11-19 17:37)\n",
    "    '''\n",
    "    if s1_body == s1:\n",
    "        s1_body = s1[1:-1]\n",
    "    if s2_body == s2:\n",
    "        s2_body = s2[1:-1]\n",
    "    '''\n",
    "    \n",
    "    # return true only if start and end are okay\n",
    "    return (startOk and endOk), s1_body, s2_body\n",
    "\n",
    "\n",
    "'''\n",
    "restDiffOk: checks if diff letters are indeed all in at least one mix \n",
    "            @param remove the items to be removed from diff\n",
    "            @param s1 string1\n",
    "            @param s2 string2\n",
    "'''\n",
    "def restDiffOk(diff, remove, s1, s2, mixes):\n",
    "    diff = list(set(diff) - set(remove))\n",
    "    \n",
    "    for d in diff:\n",
    "        noD = s1 if d not in s1 else s2\n",
    "        hasD = s1 if d in s1 else s2\n",
    "        \n",
    "        for m in mixes:\n",
    "            if d in m:\n",
    "                g = list(set(m) - set(d))\n",
    "                count = 0\n",
    "                for i in g:\n",
    "                    if i in noD:\n",
    "                        count += 1\n",
    "                    if count == len(g):\n",
    "                        return True\n",
    "                    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"assets/img/israel.png?v=1\" width=\"8%\" height=\"8%\" alt=\"Functions for Hebrew\">\n",
    "    <h3>Functions for Hebrew:</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "allCombChecks: check all specific combinations \n",
    "'''\n",
    "def allCombChecks(s1, s2, body1, body2):\n",
    "    diff = removeSharedLetters(body1, body2)\n",
    "    \n",
    "    # e.g. rayinu - rainu ראינו\n",
    "    if isEqualOnRemove(\"yi\", \"i\", s1, s2) and \"y\" in diff:\n",
    "        return True\n",
    "    \n",
    "    # e.g. beyit - beyt בית\n",
    "    if isEqualOnRemove(\"yi\", \"y\", s1, s2) and \"i\" in diff:\n",
    "        return True\n",
    "    \n",
    "    # e.g. yihiye - hihiye\n",
    "    if isEqualOnRemove(\"hi\", \"yi\", s1, s2):\n",
    "        return True\n",
    "    \n",
    "    # e.g. yihiye yihye diff\n",
    "    if isEqualOnRemove(\"iy\", \"y\", s1, s2) and \"i\" in diff:\n",
    "        return True\n",
    "        \n",
    "    # e.g. matay - matai | layla, laila | eyx, eix\n",
    "    if \"i\" in diff and \"y\" in diff and restDiffOk(diff, \"iy\", body1, body2, ALLOWED_DIFF_HEB):\n",
    "        s1_VY = hasVC(body1, consonant = \"y\")\n",
    "        s1_VI = hasVC(body1, consonant = \"i\")\n",
    "        s2_VY = hasVC(body2, consonant = \"y\")\n",
    "        s2_VI = hasVC(body2, consonant = \"i\")\n",
    "        if (s1_VY and s2_VI) or (s2_VY and s1_VI):\n",
    "            return True\n",
    "    \n",
    "    # do advanced replacements?\n",
    "    if ADVANCED_LANG_REPLACE:\n",
    "        # e.g. savta - safta | lisxov - lisxof\n",
    "        if \"f\" in diff and \"v\" in diff and restDiffOk(diff, \"iy\", body1, body2, ALLOWED_DIFF_HEB):\n",
    "            s1_Vv = hasVC(body1, consonant = \"v\")\n",
    "            s1_Vf = hasVC(body1, consonant = \"f\")\n",
    "            s2_Vv = hasVC(body2, consonant = \"v\")\n",
    "            s2_Vf = hasVC(body2, consonant = \"f\")\n",
    "            if (s1_Vv and s2_Vf) or (s2_Vv and s1_Vf):\n",
    "                return True\n",
    "\n",
    "        # CVC mil'el vowel swaps: if consonant-vowel-consonant and mil'el, e.g. mEciq - mAciq. (Note: only A-E and E-I replacements!)\n",
    "        # problem with nouns: milon - melon @Rony\n",
    "        if max(len(s1), len(s2)) <= 4 or s1[-3:] == s2[-3:]: # check if last 3 chars are the same\n",
    "            if (hasCVC(s1, vowel = \"i\", milra = False) and hasCVC(s2, vowel = \"e\", milra = False)) or (hasCVC(s1, vowel = \"e\", milra = False) and hasCVC(s2, vowel = \"i\", milra = False)) and \"e\" in diff and \"i\" in diff:\n",
    "                return True\n",
    "            elif (hasCVC(s1, vowel = \"a\", milra = False) and hasCVC(s2, vowel = \"e\", milra = False)) or (hasCVC(s1, vowel = \"e\", milra = False) and hasCVC(s2, vowel = \"a\", milra = False)) and \"a\" in diff and \"e\" in diff:\n",
    "                return True\n",
    "    \n",
    "    # e.g. raaa - raa ראה\n",
    "    if isEqualOnRemove(\"aaa\", \"aa\", body1, body1) and \"a\" in diff:\n",
    "        return True\n",
    "    \n",
    "    # e.g. eyze - eyzeh, ayom - hayom\n",
    "    if check_h(s1, s2, diff):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "'''\n",
    "isNikud: checks if a letter is a vowel\n",
    "'''\n",
    "def isNikud(letter):\n",
    "    if letter in VOWELS:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "'''\n",
    "check_h: take two words and checks if there's h in the beginning or ending of one word that is preceeded or followed\n",
    "         by a vowel, and not in the other word e.g. eyze - ezyeh, hayom - ayom\n",
    "'''\n",
    "def check_h(s1, s2, diff, onlyEdges = False):\n",
    "    # e.g. hayom - ayom\n",
    "    if (s1[0] == \"h\" and isNikud(s1[1]) and isNikud(s2[0])):\n",
    "        return True\n",
    "    # e.g. eyzeh - eyze\n",
    "    if (s1[-1] == \"h\" and isNikud(s1[-2]) and isNikud(s2[-1])):\n",
    "        return True\n",
    "    # e.g. ayom - hayom\n",
    "    if (s2[0] == \"h\" and isNikud(s2[1]) and isNikud(s1[0])):\n",
    "        return True\n",
    "    # e.g. eyze - eyzeh\n",
    "    if(s2[-1] == \"h\" and isNikud(s2[-2]) and isNikud(s1[-1])):\n",
    "        return True\n",
    "    \n",
    "    # Default: if we are not checking only the edges of the words\n",
    "    if not onlyEdges:\n",
    "        # if h is preceded and follwed by a vowel, e.g. imahot - imaot אמהות\n",
    "        if \"h\" in diff:\n",
    "            hasH = s1 if \"h\" in s1 else s2\n",
    "            noH = s1 if \"h\" not in s1 else s2\n",
    "            # check if one word has VHV and the other has VV\n",
    "            if hasVCV(hasH, consonant = \"h\") and hasCV(noH, consonant = VOWELS):\n",
    "                return True\n",
    "\n",
    "        # e.g. haimahot - haimaot\n",
    "        elif \"h\" in s1 or \"h\" in s2:\n",
    "            s1_VHV = hasVCV(s1, consonant = \"h\")\n",
    "            s2_VHV = hasVCV(s2, consonant = \"h\")\n",
    "            if (s1_VHV and not s2_VHV) or (s2_VHV and not s1_VHV):\n",
    "                return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "\n",
    "'''\n",
    "shouldMerge_heb: check if two strings are similar enough transcription-wise to be merged\n",
    "'''\n",
    "def shouldMerge_heb(s1, s2):\n",
    "    diff = removeSharedLetters(s1, s2)\n",
    "    \n",
    "    # First and strongest filter: if the difference has letters other than specified, don't merge!\n",
    "    if not hasOnly(diff, ALLOWED_LETTERS_HEB):\n",
    "        return False\n",
    "    \n",
    "    # check of the difference contains at least one of the ALLOWED_DIFF_HEB\n",
    "    mixExists = False\n",
    "    for mix in ALLOWED_DIFF_HEB:\n",
    "        if \"\".join(diff) == mix:\n",
    "            mixExists = True\n",
    "            break\n",
    "    \n",
    "    # check if the strings' edges are identical\n",
    "    edgesOk_1, body1, body2 = isEdgeLettersSame(s1, s2, LETTER_REPLACEMENTS_HEB[0])\n",
    "    edgesOk_2, body3, body4 = isEdgeLettersSame(s1, s2, LETTER_REPLACEMENTS_HEB[1])\n",
    "    \n",
    "    if (edgesOk_1 or edgesOk_2) or check_h(s1, s2, diff, onlyEdges = True):\n",
    "        # if their body is the same\n",
    "        if body1 == body2 or body3 == body4:\n",
    "            return True\n",
    "        elif mixExists:\n",
    "            return True\n",
    "        # check the h differences (article, VHV etc.)\n",
    "        elif check_h(s1, s2, diff):\n",
    "            return True\n",
    "        # now perform the heaviest check (contains check_h())\n",
    "        elif allCombChecks(s1, s2, body1, body2) or allCombChecks(s1, s2, body3, body4):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"assets/img/russia.png\" width=\"10%\" height=\"10%\" alt=\"Functions for Russian\">\n",
    "    <h3>Functions for Russian:</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shouldMerge_rus: check if two strings are similar enough transcription-wise to be merged\n",
    "'''\n",
    "def shouldMerge_rus(s1, s2):\n",
    "    diff = removeSharedLetters(s1, s2)\n",
    "\n",
    "    # if the difference between the words is one of following leteters, then they shouldn't merge\n",
    "    for letter in diff:\n",
    "        if letter in PROHIBITED_LETTERS_RUS:\n",
    "            return False\n",
    "    \n",
    "    # edge letters must be the same in both words\n",
    "    edgesOk1, body1, body2 = isEdgeLettersSame(s1, s2, LETTER_REPLACEMENTS_RUS)\n",
    "    edgesOk2, body3, body4 = isEdgeLettersSame(s1, s2, {\"go\": [\"vo\"]}, \"end\") # e.g. ego - evo\n",
    "    if (edgesOk1 or edgesOk2) and (body1 == body2 or body3 == body4):\n",
    "        return True\n",
    "    \n",
    "    '''\n",
    "    Now we are done checking the edges. Now we move to checking the insides.\n",
    "    '''\n",
    "    \n",
    "    # if y is not the last letter in both words (because it makes the word plural: e.g. kot - koty, kust - kusty)\n",
    "    if \"y\" in diff and s1[-1] != \"y\" and s2[-1] != \"y\":\n",
    "        hasY = s1 if \"y\" in s1 else s2\n",
    "        # if y is preceded by a vowel (e.g. vstretil vstreytil) or followed by j (e.g. kotoruyu  - kotoruju)\n",
    "        if hasVC(hasY, consonant = \"y\") or \"yj\" in hasY:\n",
    "            return True\n",
    "    \n",
    "    # if both word are almost the same (until last 2 chars)\n",
    "    # and if one word end with \"yj\" and the other with \"y\", e.g. kotoryj - kotory\n",
    "    if s1[:-2] == s2[:-2] and (s1[-2:] == \"yj\" and s2[-1] == \"y\") or (s2[-2:] == \"yj\" and s1[-1] == \"y\"):\n",
    "        return True\n",
    "        \n",
    "    # check for j:\n",
    "    # 1. don't merge bashnU - bashnJU 2. continue if both don't end with j\n",
    "    # Note: I should have added \"a\" to vowels in both hasCV but then I can't merge prosnJEmsJA - prosnEmsJA cuz it has double CV\n",
    "    elif (isEqualOnRemove(\"j\", \"\", s1, s2) and not hasCV(s1, consonant = \"j\", vowel = \"iou\") and not hasCV(s2, consonant = \"j\", vowel = \"iou\")\n",
    "          and s1[-1] != \"j\" and s2[-1] != \"j\" and \"j\" in diff):\n",
    "        return True\n",
    "    \n",
    "    # e.g. devocka - devochka\n",
    "    if isEqualOnRemove(\"ck\", \"chk\", s1, s2) and \"h\" in diff:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"assets/img/hamming.png\" width=\"10%\" height=\"10%\">\n",
    "    <h3>Calculate the similarity of a pair of words and decide whether they should merge:</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "shouldMerge: according to the language, apply the function that checks if two strings are similar enough\n",
    "             transcription-wise to be merged\n",
    "'''\n",
    "def shouldMerge(capsule, lang, threshold, exclude_pairs):\n",
    "    s1 = capsule[0]\n",
    "    freq1 = capsule[1]\n",
    "    s2 = capsule[2]\n",
    "    freq2 = capsule[3]\n",
    "    sim = capsule[4]\n",
    "    maxLen = max(len(s1), len(s2))\n",
    "    \n",
    "    # block low similarity\n",
    "    if not (sim >= threshold or (maxLen == 4 and sim >= 0.6) or (maxLen == 3 and sim >= 0.5)):\n",
    "        return False\n",
    "    \n",
    "    # check if the pair is excluded\n",
    "    if s1 in exclude_pairs and exclude_pairs[s1] == s2:\n",
    "        return False\n",
    "    elif s2 in exclude_pairs and exclude_pairs[s2] == s1:\n",
    "        return False\n",
    "    \n",
    "    # allow typos\n",
    "    if typosStats(capsule):\n",
    "        return True\n",
    "    \n",
    "    # proceed by lanugage\n",
    "    lang = lang.lower()\n",
    "    if lang == HEBREW:\n",
    "        return shouldMerge_heb(s1, s2)\n",
    "    elif lang == RUSSIAN:\n",
    "        return shouldMerge_rus(s1, s2)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "        \n",
    "'''\n",
    "typosStats: check for transcribers' typos in words?\n",
    "            Note: we can't know if it's a typo or if it's something that the child did say.\n",
    "            Thus for now I recommend defining CHECK_FOR_TYPOS = False\n",
    "'''\n",
    "def typosStats(capsule):\n",
    "    if not CHECK_FOR_TYPOS:\n",
    "        return False\n",
    "    \n",
    "    sim = capsule[4]\n",
    "    if sim < 0.9:\n",
    "        return False\n",
    "    \n",
    "    # frequency of word1\n",
    "    freq1 = capsule[1]\n",
    "    # frequency of word2\n",
    "    freq2 = capsule[3]\n",
    "        \n",
    "    if (min(freq1, freq2) / (freq1 + freq2) <= 0.1) and min(freq1, freq2) <= 3:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "'''\n",
    "similar: get the similarity percentage of two words\n",
    "'''\n",
    "def similar(a, b, algo = \"difflib\"):\n",
    "    if algo == \"difflib\":\n",
    "        return difflib.SequenceMatcher(None, a, b).ratio()\n",
    "    elif algo == \"lev\":\n",
    "        return Levenshtein.ratio(a, b)\n",
    "    elif algo == \"sor\":\n",
    "        return 1 - distance.sorensen(a, b)\n",
    "    elif algo == \"jac\":\n",
    "        return 1 - distance.jaccard(a, b)\n",
    "\n",
    "    \n",
    "'''\n",
    "hamming: get the hamming distance of two strings\n",
    "'''\n",
    "def hamming(s1, s2):\n",
    "    return sum(ch1 != ch2 for ch1,ch2 in zip(s1,s2))\n",
    "\n",
    "\n",
    "'''\n",
    "find_sim: returns a dictionary of pairs of similar words that should be merged\n",
    "          @param exclude_pairs pairs to be excluded\n",
    "'''\n",
    "def find_sim(freq, lang, threshold, exclude_pairs):\n",
    "    count = 0\n",
    "    count_bad = 0\n",
    "    word_list = list(freq)\n",
    "    replacements = {}\n",
    "    bad = {}\n",
    "    \n",
    "    for i, word in enumerate(freq):\n",
    "        for j in range(i):\n",
    "            word2 = word_list[j]\n",
    "            # calculate similarity percentage using difflib algorithm\n",
    "            sim = similar(word, word2)\n",
    "            # wrap all in a capsule\n",
    "            capsule = [word, freq[word], word2, freq[word2], sim]\n",
    "            \n",
    "            # check if the words should really merge\n",
    "            if shouldMerge(capsule, lang, threshold, exclude_pairs):\n",
    "                ##print(word, word2, freq[word], freq[word2], sim)\n",
    "                replacements[word] = word2\n",
    "                count += 1\n",
    "            else:\n",
    "                if lang == HEBREW:\n",
    "                    allowed_letters = ALLOWED_LETTERS_HEB\n",
    "                elif lang == RUSSIAN:\n",
    "                    allowed_letters = ALLOWED_LETTERS_RUS\n",
    "                \n",
    "                diff = removeSharedLetters(word, word2)\n",
    "                # First and strongest filter: if the difference has letters other than specified, it's not interesting!\n",
    "                # Also, don't show article difference, e.g. hayom - yom\n",
    "                if not hasOnly(diff, allowed_letters) or (word[:2] == \"ha\" and word2[:2] != \"ha\") or (word2[:2] == \"ha\" and word[:2] != \"ha\"): ###\n",
    "                    continue\n",
    "                \n",
    "                if sim >= threshold:\n",
    "                    bad[word] = word2\n",
    "                    count_bad += 1\n",
    "                \n",
    "    return (replacements, bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"assets/img/replace.png\" width=\"10%\" height=\"10%\" alt=\"Helper functions for replacing\">\n",
    "    <h3 align=\"center\">Helper functions for replacing:</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "xlsColIndex: convert Excel column to index, e.g. Z -> 25 | CH -> 85\n",
    "'''\n",
    "def xlsColIndex(col):\n",
    "    col = col.lower()\n",
    "    if len(col) == 1:\n",
    "        return ord(col[0]) - 97\n",
    "    elif len(col) == 2:\n",
    "        return (ord(col[0]) - 97 + 1) * 26 + (ord(col[1]) - 97)\n",
    "\n",
    "'''\n",
    "replaceInDataFrame: applies the replacements in the dataframe\n",
    "'''\n",
    "def replaceInDataFrame(df, colname, replacements, lang):\n",
    "    \n",
    "    if lang == HEBREW:\n",
    "        remove_symbols = REMOVE_SYMBOLS_HEB\n",
    "        \n",
    "    elif lang == RUSSIAN:\n",
    "        remove_symbols = REMOVE_SYMBOLS_RUS\n",
    "    \n",
    "    # replace symbols\n",
    "    for orig, rep in REPLACE_SYMBOLS.items():\n",
    "        df[colname] = df[colname].str.replace(r\"\" + orig, rep)\n",
    "    \n",
    "    # remove symbols, @ marks, XXXX, N/A\n",
    "    pattern = r\"[\\\\\"+ \"\\\\\".join(remove_symbols) + r\"]|@[\\w\\:\\.\\;]{0,}|\\b(\\w*[Xx]+\\w*)\\b|[Nn]\\/[Aa]|^N$|^A$\"\n",
    "    df[colname] = df[colname].str.replace(pattern, '')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # trim and remove multiple spaces\n",
    "    df[colname] = df[colname].str.strip()\n",
    "    df[colname] = df[colname].str.replace(\"([\\s]+)\", ' ')\n",
    "    \n",
    "    # finally replace the words\n",
    "    if len(replacements) > 0:\n",
    "        replacements = {r'\\b{}\\b'.format(k):v for k, v in replacements.items()}\n",
    "        df[colname] = df[colname].replace(to_replace = replacements, regex=True)\n",
    "    \n",
    "    # replace NaN with blank in all rows\n",
    "    df[colname].replace(np.nan, '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"assets/img/start95.jpg\" width=\"20%\" height=\"20%\" alt=\"Main\">\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MAIN\n",
    "NOTE: once main is run, the dataframe changes, i.e. the replacements are applied to the original dataframe\n",
    "      and will stick untill the excel file is read again.\n",
    "'''\n",
    "def main(interest = \"good\", language = \"\", threshold = SIMILARITY_THRESHOLD, exclude_pairs = {}, df = df, doPrint = True):\n",
    "    if doPrint:\n",
    "        print(\"Threshold:\", threshold)\n",
    "    \n",
    "    # convert all cells that has only a number (int cell) to string\n",
    "    # https://stackoverflow.com/questions/48978151/why-does-pandas-series-str-convert-numbers-to-nan\n",
    "    # Does not work for some reason @Rony\n",
    "    # df = df.apply(lambda x: x.apply(str) if x.dtype == 'object' else x)\n",
    "    \n",
    "    # total replacements counter\n",
    "    total_good_count = 0\n",
    "    total_bad_count = 0\n",
    "    \n",
    "    # while true is needed to merge multiple words into a single word, e.g. if \"hatul\" -> \"chatul\" and \"xatull\" -> \"xatul\"\n",
    "    # so thanks to while true we'll be able to merge \"chatul\" -> \"xatul\"\n",
    "    while True:\n",
    "        last_count = total_good_count\n",
    "        \n",
    "        for lang, rang in LANGUAGES.items():\n",
    "\n",
    "            if language not in lang:\n",
    "                continue\n",
    "            \n",
    "            for i in range (xlsColIndex(rang[0]), xlsColIndex(rang[1]) + 1):\n",
    "                colname = df.columns[i]\n",
    "                heb_data = df[colname]\n",
    "                heb_freq = loop_freq(heb_data, lang)\n",
    "                replacements, bad = find_sim(heb_freq, lang, threshold, exclude_pairs)\n",
    "                \n",
    "                good_count = len(replacements)\n",
    "                bad_count = len(bad)\n",
    "                # apply replacements\n",
    "                replaceInDataFrame(df, colname, replacements, lang)\n",
    "\n",
    "                if good_count > 0 and interest in [\"good\", BOTH]:\n",
    "                    if doPrint:\n",
    "                        print(\"--------------------------\")\n",
    "                        print(lang + \": \" + str(replacements))\n",
    "                    # update the total replacements counter\n",
    "                    total_good_count += good_count\n",
    "\n",
    "                if bad_count > 0 and interest in [\"bad\", BOTH]:\n",
    "                    if doPrint:\n",
    "                        print(\"--------------------------\")\n",
    "                        print(lang + \": \" + str(bad))\n",
    "                    total_bad_count += bad_count\n",
    "        \n",
    "        # exit while loop if no any new good replacements \n",
    "        if last_count == total_good_count:\n",
    "            break\n",
    "\n",
    "    if doPrint:\n",
    "        print(\"\\nTotal replacements: \" + str(total_good_count))\n",
    "        print(\"\\nTotal ignored: \" + str(total_bad_count))\n",
    "\n",
    "        # print inspections\n",
    "        if len(INSPECT) > 0:\n",
    "            print(\"*** Inspect problematic cells: \" + \" | \".join(INSPECT))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
